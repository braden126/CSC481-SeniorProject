---
title: "Moodle Group 1 Qs"
author: "Braden Baker"
date: "3/24/2021"
output:
  html_document: default
  word_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(lubridate)
library(chron)
library(rebus)
library(stringr)
library(corrplot)
library(ggpubr)
library(ggthemes)
library(scales)
library(plotly)
library(ggrepel)
library(readxl)

#base classes
com101 <- read_csv("logs_COM101.A1,COR220C.A1,GIS295.A1A1-2020FALLMain_20210226-0953.csv")  # 25 students T/TR 2:30 - 3:50
psy101 <- read_csv("logs_COR220PW.B1,PSY101.B1B1-2020FALLMain_20210226-0959.csv")  # 25 students M/W  2:00 - 3:50
eng101 <- read_csv("logs_ENG101Web-2020FALL01_20210225-1519.csv")                           # 2 students  online
mth101 <- read_csv("logs_MTH101A1-2020FALLMain_20210226-1001.csv")                          # 24 students T/TR 2:30 - 3:50
art157 <- read_csv("logs_ART157.WEB,COR240A.WEBWEB-2021SPR01_20210226-0951.csv")            # 22 students online

#plugin classes
ge206 <- read_excel("logs_GE 206A2-2021SPRMain_20210318-0944.xlsx") #7 students MWF 9:00 - 9:50
ce435 <- read_csv("logs_CE 435.A2,MCE535.A2A2-2021SPRMain_20210318-0947.csv") # 8 students W 5:00 - 7:50

cor120 <- read_csv("logs_COR120C2-2021SPRMain_20210318-0949.csv") #14 students T/TR 12:30 - 2:20
eng210 <- read_csv("logs_COR210YW.A2,ENG210.B2A2-2021SPRMain_20210318-0951.csv") # 20 students MW 2:00 - 3:50

ba420 <- read_csv("logs_BA 420A2-2021SPRMain_20210318-0959.csv") # 23 students arranged
ba330 <- read_csv("logs_BA 330A2-2021SPRMain_20210318-0954.csv") # 25 students MWF 10:00 - 10:50
ba431 <- read_csv("logs_BA 431A2-2021SPRMain_20210318-0957.csv") # 13 students MWF 2:00 - 2:50
ba344 <- read_csv("logs_BA 344A2-2021SPRMain_20210318-0955.csv") # 17 students MWF 9:00 - 9:50

clean <- function(dataframe) {
  
  #fix column names
  dataframe <- dataframe %>%
    rename(Eventcontext = `Event context`,
           Eventname = `Event name`,
             ) 
  
  #make time coloumn usable 
  dataframe$Time <- as.POSIXct(dataframe$Time, format = "%m/%d/%Y, %H:%M")
  dataframe$roundedtime <- round_date(dataframe$Time,unit="hour")
  
  dataframe$month = as.numeric(format(dataframe$roundedtime, "%m"))
  dataframe$day = as.numeric(format(dataframe$roundedtime, "%d"))
  dataframe$year = as.numeric(format(dataframe$roundedtime, "%Y"))
  dataframe$roundedtime = format(dataframe$roundedtime, "%H:%M")
  
  dataframe$weekday <- wday(dataframe$Time, label=TRUE)
  dataframe$week <- epiweek(dataframe$Time) #new week starts sunday
  
  #extract Moodle assigned userid to be an identifier 
  dataframe$userid <- str_extract(dataframe$Description, pattern = 
                                    one_or_more("'") %R%
                                    capture(one_or_more(DGT)) %R%
                                    one_or_more("'")
  )
  
  dataframe$userid <- gsub("'", "", dataframe$userid)
  
  return(dataframe)
}

#clean classes

com101 <- clean(com101)
com101$classname <- "com101"
com101$testgroup <- 0
com101$numStudents <- 25
com101$class <- "Class1"

psy101 <- clean(psy101)
psy101$classname <- "psy101"
psy101$testgroup <- 0
psy101$numStudents <- 25
psy101$class <- "Class2"

eng101 <- clean(eng101)
eng101$classname <- "eng101"
eng101$testgroup <- 0
eng101$numStudents <- 2
eng101$class <- "Class3"

mth101 <- clean(mth101)
mth101$classname <- "mth101"
mth101$testgroup <- 0
mth101$numStudents <- 24
mth101$class <- "Class4"

art157 <- clean(art157)
art157$classname <- "art157"
art157$testgroup <- 0
art157$numStudents <- 22
art157$class <- "Class5"

#############
ge206 <- clean(ge206)
ge206$classname <- "ge206"
ge206$testgroup <- 1
ge206$numStudents <- 7
ge206$class <- "Class6"

ce435 <- clean(ce435)
ce435$classname <- "ce435"
ce435$testgroup <- 1
ce435$numStudents <- 8
ce435$class <- "Class7"
#############
cor120 <- clean(cor120)
cor120$classname <- "cor120"
cor120$testgroup <- 1
cor120$numStudents <- 14
cor120$class <- "Class8"

eng210 <- clean(eng210)
eng210$classname <- "eng210"
eng210$testgroup <- 1
eng210$numStudents <- 20
eng210$class <- "Class9"

#############
ba420 <- clean(ba420)
ba420$classname <- "ba420"
ba420$testgroup <- 1
ba420$numStudents <- 23
ba420$class <- "Class10"

ba330 <- clean(ba330)
ba330$classname <- "ba330"
ba330$testgroup <- 1
ba330$numStudents <- 25
ba330$class <- "Class11"

ba431 <- clean(ba431)
ba431$classname <- "ba431"
ba431$testgroup <- 1
ba431$numStudents <- 13
ba431$class <- "Class12"

ba344 <- clean(ba344)
ba344$classname <- "ba344"
ba344$testgroup <- 1
ba344$numStudents <- 17
ba344$class <- "Class13"

alldata <- bind_rows(
  com101,
  psy101,
  eng101,
  mth101,
  art157,
  ge206,
  ce435,
  cor120,
  eng210,
  ba420,
  ba330,
  ba431,
  ba344
)

```

## Question 1: How Long Does it Take for Students to View Their Feedback

```{r, message=FALSE, warning=FALSE, echo=FALSE}

#data setup function
q1fun <- function(dataframe) {
  
  dataframe <- dataframe %>%
    filter(Eventname %in% c("Feedback viewed", "The submission has been graded."))
  
  dataframe$tempassignmentid <- str_extract_all(dataframe$Description, pattern = 
                                           one_or_more("'") %R%
                                           capture(one_or_more(DGT)) %R%
                                           one_or_more("'")
  )
  
  dataframe$tempassignmentid <- sapply(dataframe$tempassignmentid, paste, collapse = ",")
  dataframe$tempassignmentid <- str_replace_all(dataframe$tempassignmentid, "'", "")
  dataframe <- separate(dataframe, tempassignmentid, into = c("c1", "c2", "c3", "c4"))
  
  dataframe <- dataframe %>%
    mutate(
      assignmentid = if_else(Eventname == "Feedback viewed", dataframe$c3, dataframe$c4),
      usergraded = if_else(Eventname == "The submission has been graded.", dataframe$c3, "NA")
    ) %>%
    select(-c1, -c2, -c3, -c4) 
  
  dataframe11 <- dataframe %>%  
    filter(Eventname == "The submission has been graded.") %>%
    group_by(assignmentid, usergraded) %>% 
    slice(which.min(Time)) #only the first time an instructor graded an assignment (removes changes)
  
  dataframe12 <- dataframe %>%
    filter(Eventname == "Feedback viewed") %>%
    group_by(userid, assignmentid) %>%
    slice(which.min(Time)) #only the first time a student views feedback (removes extras)
  

  
  dataframe <- rbind(dataframe11, dataframe12)
  
  #makes sure this joined correctly
  #goal is to make sure the feedback viewed group of data has the grade grouped of data joined on the correct coloum 
  #use time differene when for sure
  dataframe <- left_join(dataframe11, dataframe12, by = c('assignmentid' = 'assignmentid','usergraded' = 'userid'))
  
  #select the first time a student viewed the assignment only
  dataframe <- dataframe %>%
    group_by(assignmentid, usergraded) %>% 
    slice(which.min(Time.y)) 
  
  fbviewedna <- as.numeric(nrow(dataframe11)) - as.numeric(nrow(dataframe)) 
  dataframe$fbnotviewed <- fbviewedna
  dataframe$fbviewed <- as.numeric(nrow(dataframe))
  return(dataframe)
}

#runs on each dataframe to elimnate duplications errors from the left join
q1<- q1fun(com101)
q2<- q1fun(psy101)
q3<- q1fun(eng101)
q4<- q1fun(mth101)
q5<- q1fun(art157)
q6<- q1fun(ge206)
q7<- q1fun(ce435)
q8<- q1fun(cor120)
q9<- q1fun(eng210)
q10<- q1fun(ba420)
q11<- q1fun(ba330)
q12<- q1fun(ba431)
q13<- q1fun(ba344)

q1data <- bind_rows(q1,
                    q2,
                    q3,
                    q4,
                    q5,
                    q6,
                    q7,
                    q8,
                    q9,
                    q10,
                    q11,
                    q12,
                    q13
)

q1data <- na.omit(q1data)



```

Most students viewed their feedback within a couple days but every class had outliers where a student would not view their feedback for days. This data also does not include students that never checked their feedback.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
q1datac <- q1data %>%
  mutate(timetoviewfb = difftime(Time.x, Time.y, units = "hours")) %>%
  filter(timetoviewfb < 0) %>% #removes a few data anomalies
  mutate(timetoviewfb = timetoviewfb * -1)

#the purpose of this graph is to show how big the outliers are - I really dont need the box plot to show that
ggplot(q1datac, aes(x=class.x, y=timetoviewfb)) + 
#  geom_boxplot(alpha=0) + 
  geom_jitter(alpha=0.3, width = 0.2, color = "#2438f0") +
  scale_y_continuous(breaks = pretty_breaks(n = 8)) +
  theme_clean() +
  labs(x = "Class Name", 
       y = "Number of Hours Between Feedback Posted and Viewed", 
       title = "How Long it Takes for Students to View Feedback")


```


Despite the outliers, 80% of student feedback was viewed within about 50 hours from the time their feedback was posted.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

q1quantile <- quantile(as.numeric(q1datac$timetoviewfb), .8)

ggplot(q1datac, aes(x= timetoviewfb)) + 
  geom_histogram(binwidth = 20, colour="white", fill="#c9401e") +
  geom_vline(xintercept=q1quantile, color="blue", linetype="dashed", size=1) +
  scale_x_continuous(breaks = pretty_breaks(n = 15)) +
  theme_clean() +
  geom_text(aes(x=q1quantile + 15, label="80% of Students", y=75), colour="blue", angle=90) + 
  labs(x = "Time Before Feedback was Viewed (Hours)", 
       y = "Count of Students", 
       title = "Time Between Feedback Posted and Viewed (Hours)")


```

When including all classes, the median time to view feedback was 17.6 hours and the mean was 521.1 hours. Here it is best to focus on the median time to view feedback to lessen the impact of the outliers.

For most classes the median time to view feedback was at or under 20 hours. Many of the classes with the largest sample sizes are in the under 20 hour group suggesting that the median is a much better representation of how long it takes for students to view feedback than the mean.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
q1datasum <- q1data %>%
  group_by(class.x) %>%
  mutate(timetoviewfb = -1 * (difftime(Time.x, Time.y, units = "hours"))) %>%
  summarise(med = median(timetoviewfb), avg = mean(timetoviewfb), SampleSize = n())

q1dataAvgMed <- q1data %>%
  ungroup() %>%
  mutate(timetoviewfb = -1 * (difftime(Time.x, Time.y, units = "hours"))) %>%
  summarise(med = round(median(timetoviewfb), 1), avg = round(mean(timetoviewfb), 1), SampleSize = n())

ggplot(q1datasum, aes(x=class.x, y = med, fill = SampleSize)) + 
  geom_col() +
  theme_clean() +
  labs(x = "Class Name", 
       y = "Median Time for Students to View Feedback (Hours)", 
       title = "Median Time for Students to View Feedback",
       subtitle = paste("Overall: Median = ", q1dataAvgMed$med, "Mean = ", q1dataAvgMed$avg))


```
```{r, message=FALSE, warning=FALSE, echo=FALSE}

# students that did not view feedback

ggplot(q1data, aes(x=class.x, y = fbnotviewed)) + geom_point() + geom_point(data = q1data, aes(x=class.y, y = fbviewed, color = "red"))

```
## Question 2:  Which Moodle Resources get the Most and Least Number of Interactions

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# set up function
q2fun <- function(dataframe) {
  #gather views per type
  numstudent <- dataframe$numStudents[1]
  dataframe2 <- dataframe
  
  dataframe$Moduletype <- str_extract(dataframe$Eventcontext, pattern = 
                                 capture(one_or_more(WRD)) %R%
                                 ":" 
  )
  
  dataframe$Moduletype <- gsub(":", "", dataframe$Moduletype)
  
  dataframe <- dataframe %>%
    filter(Eventname == 'Course module viewed') %>%
    group_by(Moduletype) %>%
    summarise(TotalModuleviews = n())
  
  #gather posts per type
  #course was restore so Course module created is not very helpful
  #instead group by event context, get n (placeholder), then count module types
  dataframe2 <- dataframe2 %>%
    group_by(Eventcontext) %>%
    summarise(count = n())
  
  dataframe2$Moduletype <- str_extract(dataframe2$Eventcontext, pattern = 
                                  capture(one_or_more(WRD)) %R%
                                  ":" 
  )
  
  dataframe2$Moduletype <- gsub(":", "", dataframe2$Moduletype)
  
  dataframe2 <- dataframe2 %>%
    group_by(Moduletype) %>%
    summarise(ModulesAdded = n())
  
  ####
  #join
  
  dataframe22 <- inner_join(dataframe, dataframe2, by = c("Moduletype" = "Moduletype")) %>%
    mutate(viewsperadd = TotalModuleviews / ModulesAdded, viewsperstudent = viewsperadd / numstudent) %>% ##22 students 
    arrange(desc(viewsperstudent))
  
  return(dataframe22)
}

q21<- q2fun(com101)
q22<- q2fun(psy101)
q23<- q2fun(eng101)
q24<- q2fun(mth101)
q25<- q2fun(art157)
q26<- q2fun(ge206)
q27<- q2fun(ce435)
q28<- q2fun(cor120)
q29<- q2fun(eng210)
q210<- q2fun(ba420)
q211<- q2fun(ba330)
q212<- q2fun(ba431)
q213<- q2fun(ba344)

q2data <- bind_rows(q21,
                    q22,
                    q23,
                    q24,
                    q25,
                    q26,
                    q27,
                    q28,
                    q29,
                    q210,
                    q211,
                    q212,
                    q213
)

q2data <- q2data %>%
  mutate(Moduletype = str_replace(Moduletype, "tool", "External Tool")) %>%
  filter(!is.na(Moduletype))


```


The assignment module type received the most views as expected. The next highest viewed were files which also had the highest number of modules added so its high view count is expected.

The viewership of URL is surprising since it had a large number of modules added. The other module types having low total viewership is expected given that there was less of those module types posted.


```{r, message=FALSE, warning=FALSE, echo=FALSE}

q2datasumtotals <- q2data %>%
  group_by(Moduletype) %>%
  summarise(
    TotalModuleviews = sum(TotalModuleviews),
    TotalModulesAdded = sum(ModulesAdded)
  ) %>%
  mutate(ViewsPerModule = TotalModuleviews / TotalModulesAdded)



ggplot(q2datasumtotals, aes(x=Moduletype, y=TotalModuleviews, fill=TotalModulesAdded)) +
  geom_col(position = "dodge") +
  theme_clean() +
  labs(x = "Module Type", 
       y = "Views",
       title = "How Much Each Moodle Resource is Interacted",
       subtitle = "Total Views for each Module Type") +
  geom_text(aes(label = TotalModuleviews), vjust = -0.125) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) 

q2datasumtotals


# ggplot(q2datalong, aes(x=Moduletype, y=Value, fill=Measure)) +
#   geom_col(position = "dodge") +
#   theme_clean() +
#   labs(x = "Module Type", 
#        y = "Count",
#        title = "How Much Each Moodle Resource is Interacted",
#        subtitle = "Averages of Course Totals")

```

When looking at views per module, glossary is clearly at the top. Only one glossary module was posted in the sample of logs but 450 views is very high and suggests it was used by students frequently. The choice model was similar, it was only used in one course but received quite a few views.

Outside of glossary and choice, assignment and quiz received the most views per module posted. This is likely because students have to interact with these for grade as opposed to viewing a file or URL that are not always required.

Forums also had an amount of views per module posted similar to quizzes suggesting that when forums are used, students are willing to interact with them as much as they do with another important module type.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
ggplot(q2datasumtotals, aes(x=Moduletype, y=ViewsPerModule, fill=TotalModulesAdded)) +
  geom_col(position = "dodge") +
  theme_clean() +
  labs(x = "Module Type", 
       y = "Views",
       title = "How Much Each Moodle Resource is Interacted",
       subtitle = "Views Per Module Added for each Module Type") +
  geom_text(aes(label = round(ViewsPerModule)), vjust = -0.125) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) 




```

Students viewed most modules 1-2 times with the exception of assignments, choices, folders, and quizzes that were viewed 3-7 times.  

File and URL module types were both viewed about 1 time per student. Most lecture materials are posted as those modules types so I would have expected them to have more viewership. Two possible reasons to explain this are that students could be returning to downloaded copies of files which would eliminate the need for to view the module again. Similarly they could be going directly to a URL instead of clicking on the module. The other possible reason could be that students are leaving files and URLs open until they are done working with them.

*How to read: The assignment module received an average of 103.5 views on each module posted, each student viewed an assignment module on average 6.7 times, and each class had an average of 9.8 assignment modules added*
```{r, message=FALSE, warning=FALSE, echo=FALSE}

q2datasum <- q2data %>%
  group_by(Moduletype) %>%
  summarise(
    AVGTotalModuleviews = mean(TotalModuleviews),
    AVGModulesAdded = mean(ModulesAdded),
    AVGViewsPerModule = mean(viewsperadd),
    AVGModuleViewsPerStudent = mean(viewsperstudent)
  )

q2datalong <- q2datasum %>%
  pivot_longer(
    cols = c(AVGTotalModuleviews, AVGModulesAdded, AVGViewsPerModule, AVGModuleViewsPerStudent),
    names_to = "Measure",
    values_to = "Value"
  )

q2datalongnoviews <- q2datasum %>%
  pivot_longer(
    cols = c(AVGTotalModuleviews, AVGModulesAdded, AVGViewsPerModule, AVGModuleViewsPerStudent),
    names_to = "Measure",
    values_to = "Value"
  ) %>%
  filter(Measure != "AVGTotalModuleviews" & Moduletype != "Glossary")


ggplot(q2datalongnoviews, aes(x=Moduletype, y=Value, fill=Measure)) + 
  geom_col() +
  theme_clean() +
  labs(x = "Module Type", 
       y = "Count", 
       title = "How Much Each Moodle Resource is Interacted",
       subtitle = "Average of Class Totals, Glossary Removed") +
  geom_text(aes(label = round(Value, 1)), size = 3,  position = position_stack(vjust = .5)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

select(q2datasum, -AVGTotalModuleviews)

```

## How Often are Students Viewing Recorded Lectures?

```{r, message=FALSE, warning=FALSE, echo=FALSE}

#clean data
q31 <- mth101 %>%
  filter(str_detect(Eventcontext, "URL: Lecture Video") & Eventname == 'Course module viewed') %>%
  group_by(Eventcontext) %>%
  summarise(Views = n()) %>%
  mutate(Eventcontext = str_replace(Eventcontext, "URL: Lecture Video for ", ""),
         Eventcontext = str_replace(Eventcontext, "URL: Lecture Video For ", ""),
         Date = as.Date(Eventcontext, "%a, %B %d, %y")) %>%
  arrange(Date) %>%
  mutate(Date = factor(Date, labels=format(Date,"%m-%d"), ordered=TRUE)) 

```

Only one class in the sample of logs posted recorded lectures consistently so this is a small sample size. In that class viewership mostly stayed the same throughout the semester, each recording was viewed 3-9 times out of a class size of 24.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(q31, aes(x=Date, y=Views)) + 
  geom_col(fill = "#2438f0") +
  theme_clean() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  labs(x = "Recording Posted Date",
       y = "Number of Views",
       title = "Views For Each Recorded Lecture")

```

Most students viewed a recorded lecture within about 5 days of a recording being posted. However another decently sized group viewed recorded lectures 13+ days after the recording was posted.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
#how many days after post do students watch

q321 <- mth101 %>%
  filter(str_detect(Eventcontext, "URL: Lecture Video") & Eventname == 'Course module created')

q322 <- mth101 %>%
  filter(str_detect(Eventcontext, "URL: Lecture Video") & Eventname == 'Course module viewed')

q32 <- inner_join(q322, q321, by = c("Eventcontext" = "Eventcontext"))

q32 <- q32 %>%
  mutate(timetoview = difftime(Time.x, Time.y, units = "days")) 

q3quantile <- quantile(as.numeric(q32$timetoview), .8)

ggplot(q32, aes(x=timetoview)) + 
  geom_histogram(binwidth = 1, colour="white", fill = "#c9401e") +
  geom_vline(xintercept=q3quantile, color="blue", linetype="dashed", size=1) +
  scale_x_continuous(breaks = pretty_breaks(n = 16)) +
  theme_clean() +
  geom_text(aes(x=q3quantile + 0.5, label="80% of Students", y=30), colour="blue", angle=90) + 
  labs(x = "Time Between Lecture Recording Post and View (Days)", 
       y = "Count of Students", 
       title = "Distribution of When Students View Lecture Recordings")
```


Examining further, it does seem that there may be two groups of views for recording lectures. One group views a few days after a recording is posted likely for homework, missing the class, or just going over it again. A second group views the recorded lecture days after it was posted likely for test preparation. This trend is strongest in November. Most November lectures received more views than other months 5+ days after the lecture was posted suggesting that the views may have been for preparing for end of semester exams or finals.


```{r, message=FALSE, warning=FALSE, echo=FALSE}
q32 <- q32 %>%
  mutate(Eventcontext = str_replace(Eventcontext, "URL: Lecture Video for ", ""),
         Eventcontext = str_replace(Eventcontext, "URL: Lecture Video For ", ""),
         Date = as.Date(Eventcontext, "%a, %B %d, %y"))

ggplot(q32, aes(x=reorder(Eventcontext, Time.y), y =timetoview)) + 
  coord_flip() + 
  geom_jitter(width = 0.1, color = "#c9401e", size = 2, alpha = 0.75) +
  theme_minimal() +
  labs(x = "Lecture Recording", 
       y = "Time Between Lecture Recording Post and View (Days)", 
       title = "When Students View Lecture Recordings")

```


## Checklist Module Analysis

```{r, message=FALSE, warning=FALSE, echo=FALSE}

checklist <- cor120 %>%
  filter(Component == 'Checklist' & userid != 6989 & !(Eventname %in% c("Edit page viewed", 
                                                       "Report viewed", 
                                                       "Course module instance list viewed",
                                                       "Checklist complete",
                                                       "Teacher checks updated"))) %>% #edit page and report are done by instructor only
  group_by(week, Eventname) %>%
  summarise(count = n())

checklist2 <- eng210 %>%
  filter(Component == 'Checklist' & userid != 6989 & !(Eventname %in% c("Edit page viewed",
                                                       "Report viewed",
                                                       "Course module instance list viewed",
                                                       "Checklist complete",
                                                       "Teacher checks updated" ))) %>% #edit page and report are done by instructor only
  group_by(week, Eventname) %>%
  summarise(count = n())

checklist3 <- bind_rows(eng210, cor120) %>%
  filter(Component == 'Checklist' & userid != 6989 & !(Eventname %in% c("Edit page viewed",
                                                       "Report viewed",
                                                       "Course module instance list viewed",
                                                       "Checklist complete",
                                                       "Teacher checks updated"))) %>% #edit page and report are done by instructor only
  group_by(userid) %>%
  summarise(count = n())

```

Overall, checklists received a good amount of usage in both of the classes they were used in. In each class, the amount of times students looked at checklists seems to related to how often they actually "checked" activities.

Both classes were very up and down in their usage but I assume this is just due to fluctuations in workload each week leading to less checks needing to be made for the weekly list.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

#last checklist was posted week 9 which explains drop at the end -- students actually went back and checked off old check lists last 2 weeks
ggplot(checklist, aes(x=week, y = count, color = Eventname)) + 
  geom_line(size = 2) +
  labs(x = "Week",
       y = "Number of Occurances",
       title ="Class 1 Checklist Activity") + 
  theme_minimal()

#high usage throughout
ggplot(checklist2, aes(x=week, y = count, color = Eventname)) + 
  geom_line(size = 2)  +
  labs(x = "Week",
       y = "Number of Occurances",
       title ="Class 2 Checklist Activity") + 
  theme_minimal()
    



```



Although there were students that completely ignored the checklists, most used the checklist. The average number of views plus checks was almost 30 and a decent number of students used the checklist extensively.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(checklist3, aes(x=reorder(userid, count), y = count)) + 
  geom_point(color = "red", size = 4) + 
  coord_flip() + 
  scale_y_continuous(breaks = pretty_breaks(n = 8)) +
  theme_minimal() +
  geom_hline(yintercept=mean(checklist3$count), color="blue", linetype="dashed", size=1)  +
  geom_text(aes(x=10, label=paste("Average: ", round(mean(checklist3$count),1)), y=30), colour="blue", angle=90) +
  labs(x="Student",
       y = "Total Views + Checks",
       title = "Number of Checklist Views + Checks Made by Each Student")


```


Looking at the weekly view, most students had around 5 views plus checks each week. Every week has some students using the checklist at high numbers and some barely using it the same week. I think this suggests that the usage of the checklist is dependent on how much the student wants to use the checklist rather than the number of tasks on the checklists. 

We do see that the usage of the checklists trends down slightly over the course of the semester however it is not by a significant amount.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

checklist4 <- bind_rows(eng210, cor120) %>%
  filter(Component == 'Checklist' & userid != 6989 & !(Eventname %in% c("Edit page viewed",
                                                       "Report viewed",
                                                       "Course module instance list viewed",
                                                       "Checklist complete",
                                                       "Teacher checks updated"))) %>%
  group_by(week, userid) %>%
  summarise(count = n()) 

  

#activity did trend down but not by a lot
ggplot(checklist4, aes(x=week, y=count)) + 
  geom_jitter(width = 0.1, alpha=0.5, color = "red", size = 2) + 
  geom_smooth(se = FALSE, method = "loess") + 
  theme_clean() +
  labs(x="Week",
       y = "Count",
       title = "Number of Checklist Views + Checks Made by Each Student Weekly")

```

Here is the usage of each student by week. There is a variety of patterns on display here. Some students usage of the checklists were very volatile and others stayed the same over the weeks. Some students also used the checklist less as the semester went on and some used it more. 

Unfortunately there is not enough data for fully investigate why there are so many different patterns of usage, but checklists were used considerably by students. 

*Graphs with no line are students that used the checklist only 0 or 1 times.*

```{r, message=FALSE, warning=FALSE, echo=FALSE}

#blank graphs only used the checklist once
ggplot(checklist4, aes(x=week, y=count)) + 
  geom_line(size = 1.25) + 
  geom_smooth(se = FALSE, method = lm) + 
  stat_cor(label.y = 20) +
  facet_wrap(~userid) 

```


## Perusall Module Analysis 

```{r, message=FALSE, warning=FALSE, echo=FALSE}


p1 <- cor120 %>%
  filter(Component == 'External tool' & Eventname == 'Course module viewed' & Eventcontext != "Other") %>%
  mutate(Eventcontext = str_replace(Eventcontext, "External tool: Perusall", 
                                    "External tool: Perusall a"))

p2 <- eng210 %>%
  filter(Component == 'External tool' & Eventname == 'Course module viewed' & Eventcontext != "Other") %>%
  mutate(Eventcontext = str_replace(Eventcontext, "External tool: Perusall", 
                                    "External tool: Perusall b"))

p <- bind_rows(p1, p2)


```


There were two classes that used Perusall in this dataset. The first class had a more balanced amount of activity over the weeks while the second class had a much greater amount of activity in the second half of this dataset. 


```{r, message=FALSE, warning=FALSE, echo=FALSE}

p3 <-  p %>% 
  filter(Eventname == "Course module viewed") %>%
  group_by(class, week, Eventcontext) %>%
  summarise(count = n())

ggplot(p3, aes(x = week, y = count, fill = class)) + 
  geom_col() + 
  facet_wrap(~class) +
  theme_clean() +
  labs(x = "Week",
       y = "Number of Views",
       Title = "Perusall Module Views by Week")


```
The views per student of each Perusall module was fairly spread out. Almost every Perusall module was at least viewed 1 time per student and the average was 2.3 views per student.


```{r, message=FALSE, warning=FALSE, echo=FALSE}

## views per student for each module
p4 <- p %>% 
  group_by(class, numStudents, Eventcontext) %>%
  summarise(count = n()) %>%
  mutate(Viewsperstudent = count / numStudents)

p4$names <- fct_anon(as.factor(p4$Eventcontext), prefix = "Reading ")

ggplot(p4, aes(x = reorder(names, Viewsperstudent), y = Viewsperstudent, fill = class)) +
  geom_col() +
  coord_flip() +
  geom_hline(yintercept=mean(p4$Viewsperstudent), color="blue", linetype="dashed", size=1)  +
  geom_text(aes(x=10, label=paste("Average: ", round(mean(p4$Viewsperstudent),1)), y= mean(p4$Viewsperstudent) + 0.2), colour="blue", angle=90) +
  theme_clean() +
  labs(x = "Views Per Student",
       y = "Perusall Module Name",
       title = "Views Per Student for Each Perusall Module")

```
Perusall modules were viewed by each student on average of 2.9 times. This is positive as noted previously, students viewed URL modules 0.7 times on average and file modules 1.2 times on average. 

```{r, message=FALSE, warning=FALSE, echo=FALSE}

p5 <- p %>%   
  group_by(class, userid, Eventcontext) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  group_by(class, Eventcontext) %>%
  summarise(AVGStudentVisits = mean(count)) 

p5$names <- fct_anon(as.factor(p5$Eventcontext), prefix = "Reading ")

ggplot(p5, aes(x = reorder(names, AVGStudentVisits), y = AVGStudentVisits, fill = class)) + 
  geom_col() + 
  coord_flip() +
  geom_hline(yintercept=mean(p5$AVGStudentVisits), color="blue", linetype="dashed", size=1)  +
  geom_text(aes(x=10, label=paste("Average: ", round(mean(p5$AVGStudentVisits),1)), y= mean(p5$AVGStudentVisits) + 0.2), colour="blue", angle=90) +
  theme_clean() +
  labs(x = "Perusall Module Name",
       y = "Average Number of Times Viewed by Students",
       title = "Average Number of Times Each Student Viewed Perusall Module")

```
## Overall Comparisons Between Test Classes and Regular Classes

```{r, message=FALSE, warning=FALSE, echo=FALSE}
compare <- alldata %>%
  filter(Eventname == "Course viewed") %>%
  group_by(testgroup, class, numStudents) %>%
  summarise(count = n()) %>%
  mutate(countstudentratio = count / numStudents) 

comparedatatable <- compare %>% 
  ungroup() %>%
  group_by(testgroup) %>%
  summarise(median = median(countstudentratio), avg = mean(countstudentratio))

```


Comparing the views per student of the test classes and the regular classes, the test classes had more views per student. The regular classes had an average of 126 views per student and the test classes had an average of 141 views per student, an increase of 15 students. 

While we do not have enough data here to confirm that the increase was the result of the new plug-ins rather than normal class variation, having an increase in Moodle activity in the test classes is good news for the effectiveness of the plug-ins.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(compare, aes(x=reorder(class, countstudentratio), y = countstudentratio, fill = as.factor(testgroup))) + 
  geom_col() +
  labs(x = "Class", 
       y = "Course Views Per Student", 
       title = "Course Views Per Student For Each Class") +
  theme_clean() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  geom_text(aes(label = round(countstudentratio, 1)), vjust = -0.75, size = 3)

comparedatatable

```

## When Are Students Using Moodle?

```{r, message=FALSE, warning=FALSE, echo=FALSE}
activityheatmap <- alldata %>%
  filter(Eventname == "Course viewed") %>%
  group_by(weekday, roundedtime) %>%
  summarise(count = n())

activityheatmap2 <- alldata %>%
  filter(Eventname == "A submission has been submitted.") %>%
  group_by(weekday, roundedtime) %>%
  summarise(count = n())

```

Most activity between 8:00 - 15:00 is due to classes occurring during that time range which brings students on to Moodle. 


During the weekdays, with the exception of Friday, students start viewing Moodle more often at about 18:00 and views stay high until 01:00 in the morning. These are likley the most usual hours spend on coursework. During those weekdays Tuesday and Wednesday night received more views than Thursday and Friday night suggesting the students spend less time on Moodle at the end of the week.

Friday receives by far the least amount of views with the number lowering right after 15:00 when classes end. Surprisingly, Saturday receives more Moodle views than Wednesday, Thursday and Friday. 

Sunday is as expected the day with the most activity. Starting at about 9:00, Students stay active on Sunday until 01:00 in the morning on Monday.


```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(activityheatmap, aes(roundedtime, weekday)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
  scale_fill_gradient(low = "#d8e1cf", high = "#438484", na.value = "grey50") +  
  guides(fill=guide_legend(title="Total Views")) +
  theme_minimal() + 
  labs(title = "Moodle Views by Day of Week and Hour", x = "Views Per Hour", y = "Day of Week") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text.y = element_text(face="bold"), axis.text.x =   element_text(face="bold")) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10)) +
  geom_text(aes(label = count), size = 3)

```

Here is the visualization with assignment submissions rather than course views.

Like in the graph above, the results from 8:00 - 15:00 are likely not indicative of any trends since assignments turned in at that time are likely assignments in-class assignments.

The trend of extra activity on sunday and wednesday nights continues here.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(activityheatmap2, aes(roundedtime, weekday)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
  scale_fill_gradient(low = "#d8e1cf", high = "#438484", na.value = "grey50") +  
  guides(fill=guide_legend(title="Total Submissions")) +
  theme_minimal() + 
  labs(title = "Moodle Submissions by Day of Week and Hour", x = "Submissions Per Hour", y = "Day of Week") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text.y = element_text(face="bold"), axis.text.x = element_text(face="bold"))  +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10)) +
  geom_text(aes(label = count), size = 3) 

```



```{r, message=FALSE, warning=FALSE, echo=FALSE}

timedata <- alldata %>%
  filter(Eventname == "Course viewed" | Eventname == "A submission has been submitted.")

```

Viewing interactions by only time also shows high usage during the class times from about 08:00 - 15:00. 

After 14:00, activity steadly drops until 20:00 suggesting further that this is when students start going on Moodle again after class hours. There is also a larger number of assignment submissions starting at 14:00 until 01:00 the next day.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(timedata, aes(x=roundedtime, fill = Eventname)) + 
  stat_count(position = "dodge") +
  theme_clean() +
  geom_text(aes(label = ..count..), stat = "count", position = position_dodge(width = 1),  size = 3, vjust = -0.75) +
  labs(x = "Rounded Time", 
       y = "COunt", 
       title = "Moodle Interactions by Time of Day")


```

Similarly looking at totals by day of the week, the activity of a week peaks on tuesday and then falls each day until Sunday.

```{r, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(timedata, aes(x=weekday, fill = Eventname)) + 
  stat_count(position = "dodge") +
  theme_clean() +
  geom_text(aes(label = ..count..), stat = "count", position = position_dodge(width = 1),  size = 3, vjust = -0.75) + 
  labs(x = "Weekday", 
       y = "Count", 
       title = "Moodle Interactions by Day of Week")

```
## when the assignment was assigned and the average time for student to first access the assignment, and average time for submission in relation to the due date? I sometimes would post assignments due in a week, but found the students won’t submit until the day before and I believe may not even access them until the day before. I’ve cut down on the week long assignments, and now would typically do about 4 days because of this, but would like to see some numbers that could reinforce what I think.



```{r, message=FALSE, warning=FALSE, echo=FALSE}

#data setup function
q4fun <- function(dataframe) {
  
  #fix this
  dataframe <- dataframe %>%
    filter(Eventname %in% c("Course module viewed", "A submission has been submitted."))
  
  dataframe$tempassignmentid <- str_extract_all(dataframe$Description, pattern = 
                                           one_or_more("'") %R%
                                           capture(one_or_more(DGT)) %R%
                                           one_or_more("'")
  )
  
  dataframe$tempassignmentid <- sapply(dataframe$tempassignmentid, paste, collapse = ",")
  dataframe$tempassignmentid <- str_replace_all(dataframe$tempassignmentid, "'", "")
  dataframe <- separate(dataframe, tempassignmentid, into = c("c1", "c2", "c3", "c4"))
  
dataframe <- dataframe %>%
  mutate(
    assignmentid = if_else(Eventname == "A submission has been submitted.", dataframe$c3, dataframe$c2)
  ) %>%
  select(-c1, -c2, -c3, -c4) 


dataframe11 <- dataframe %>%  
  filter(Eventname == "A submission has been submitted.") %>%
  group_by(userid, assignmentid) %>% 
  slice(which.min(Time)) #only the first time a student turned in an assignment (removes changes)

dataframe12 <- dataframe %>%
  filter(Eventname == "Course module viewed") %>%
  group_by(userid, assignmentid) %>% 
  slice(which.min(Time)) #only the first time a student viewed an assignment

  #makes sure this joined correctly
  #goal is to make sure the feedback viewed group of data has the grade grouped of data joined on the correct coloum 
  #use time differene when for sure
  dataframe <- left_join(dataframe11, dataframe12, by = c('userid' = 'userid', 'assignmentid' = 'assignmentid'))

  
  return(dataframe)
}

#runs on each dataframe to eliminate duplications errors from the left join
q1<- q4fun(com101)
q2<- q4fun(psy101)
q3<- q4fun(eng101)
q4<- q4fun(mth101)
q5<- q4fun(art157)
q6<- q4fun(ge206)
q7<- q4fun(ce435)
q8<- q4fun(cor120)
q9<- q4fun(eng210)
q10<- q4fun(ba420)
q11<- q4fun(ba330)
q12<- q4fun(ba431)
q13<- q4fun(ba344)

q4data <- bind_rows(q1,
                    q2,
                    q3,
                    q4,
                    q5,
                    q6,
                    q7,
                    q8,
                    q9,
                    q10,
                    q11,
                    q12,
                    q13
)

#q4data <- na.omit(q1data)



```

Students turned in their assignments on average 3.8 days after first viewing them. Similar to the time it took for students to viewed feedback, the median of 3 days is a good representation of the data as result of outliers from students assignments many days before submitting. 

The two highest values of turn in times were 1 and 2 days suggesting that students like complete assignments quickly once they do look at them. This data is well distributed however and there is a decent number of students in most numbers of days from view to submission.

*Note: I removed any assignment that was submitted within 1.5 hours from the first view to remove any in-class assignments or extremely short assignments from the dataset*

```{r, message=FALSE, warning=FALSE, echo=FALSE}

q41 <- q4data %>%
  mutate(timeview_submit = difftime(Time.x, Time.y, units = "days")) %>%
  filter(timeview_submit > 0.0625) ## removes anything turned in less than 1 1/2 hours to avoid in class or extremely short assignments


q4quantile <- quantile(as.numeric(q41$timeview_submit), .8)

ggplot(q41, aes(x = timeview_submit)) + 
  geom_histogram(color = "white", binwidth  = 1, fill = "#c9401e") +
  scale_x_continuous(breaks = pretty_breaks(n = 15)) +
  geom_vline(xintercept=q4quantile, color="blue", linetype="dashed", size=1) +
  geom_text(aes(x=q4quantile + 0.5, label="80% of Students", y=125), colour="blue", angle=90) +
  theme_clean() +
  labs(x = "Time Between First View and Submission (Days)",
       y = "Count",
       title = "How Long it Took Students to Submit Assignments After Viewing",
       subtitle = paste("Mean =", round(mean(q41$timeview_submit),1), "Days   Median =", round(median(q41$timeview_submit),1), "Days"))

```

Looking at the average time from first view to submission for each student by class, the times vary between classes. Some classes like class 10 and 11 are grouped tightly while others like class 1 and 9 have turn in times spread out widely.

The diverse levels of turn in times between classes suggest that class structure may have a strong impact on how long students spend between viewing and assignment and turning it in but there is not quite enough data here to confirm that assumption.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# average for each student

q42 <- q4data %>%
  mutate(timeview_submit = difftime(Time.x, Time.y, units = "days")) %>%
  filter(timeview_submit > 0.0625) %>% ## removes turned in less than 1 1/2 hours to avoid in class or extremely short assignments
  group_by(class.x, userid) %>%
  summarise(meantime = mean(timeview_submit), medtime = median(timeview_submit))

ggplot(q42, aes(x = 1:nrow(q42), y = meantime)) + 
  geom_point(color = "#2438f0", size = 2, alpha = 0.45) +
  theme_clean() +
  labs(x = "Student",
       y = "Average Time Between First View and Submission (Days)",
       title = "Average Time Between First View and Submission For Each Student")


ggplot(q42, aes(x = class.x, y = meantime, color = class.x)) + 
  geom_jitter(size = 2, alpha = 0.45, width = 0.2) +
  theme_clean() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10)) +
  labs(x = "Student",
       y = "Average Time Between First View and Submission (Days)",
       title = "Average Time Between First View and Submission For Each Student")



```

Looking at average time from first view to submission by assignment rather than class show that the bulk the data is under 10 days. Additionally, assignments with higher average view to submission times have a more spread out group of submissions while the lower average assignments tending to have tighter groupings of submissions.

The logs give no clear answer to why the groups differ because they do not capture assignment due dates, one possible reason could be that when assignments have due dates shortly after they are posted, students are forced to complete the assignment not long after they view it leading to tighter groups. Assignments posted with longer due means that students are not forcced to complete the assignment shortly after viewing leading to more flexibility in when they complete the assignment and more spread out groupings.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
##by assignment

q43 <- q4data %>%
  mutate(timeview_submit = difftime(Time.x, Time.y, units = "days")) %>%
  filter(timeview_submit > 0.0625) 

q431 <- q4data %>%
  mutate(timeview_submit = difftime(Time.x, Time.y, units = "days")) %>%
  filter(timeview_submit > 0.0625) %>%
  group_by(assignmentid) %>%
  summarise(meantime = mean(timeview_submit))

ggplot() + 
  geom_point(data = q43, aes(x=reorder(assignmentid, timeview_submit), y = timeview_submit, color = "Submission"), alpha = 0.5) +
  geom_point(data = q431, aes(x=assignmentid, y = meantime, color = "Average Submission Time"), size = 1.5) +
  scale_y_continuous(breaks = pretty_breaks(n = 15)) +
  scale_color_fivethirtyeight() +
  coord_flip() +
  theme_minimal() +
  labs(x = "Assignment ID",
        y = "Time Between First View and Submission (Days)",
        title = "Time Between First View and Submission For Each Assignment",
        subtitle = "Time of Each Submission and Average Submission Time Plotted")

```
## I would be interested in information about how often students watch any video content (whether recorded lectures or video clips). I often think these will be appealing, but I'm not sure I'm right about that!

```{r, message=FALSE, warning=FALSE, echo=FALSE}
##q51
## lecture version was already added
## str_detect "Video" or other keywords to find modules for regular

#data setup
q51 <- alldata %>%
  filter(str_detect(Eventcontext, "Video") | 
           str_detect(Eventcontext,"video") | 
           str_detect(Eventcontext, "Recording") | 
           str_detect(Eventcontext, "recording")) %>%
  filter(!str_detect(Eventcontext, "Assignment:") & #remove assignments because they are mandatory
           Eventname == "Course module viewed")


  q51$tempassignmentid <- str_extract_all(q51$Description, pattern = 
                                           one_or_more("'") %R%
                                           capture(one_or_more(DGT)) %R%
                                           one_or_more("'")
  )
  
  q51$tempassignmentid <- sapply(q51$tempassignmentid, paste, collapse = ",")
  q51$tempassignmentid <- str_replace_all(q51$tempassignmentid, "'", "")
  q51 <- separate(q51, tempassignmentid, into = c("c1", "c2"))
  
q51 <- q51 %>%
  rename(assignmentid = c2) %>%
  select(-c1) %>%
  filter(assignmentid != "571150") #removes one outlier that contains all info students need for a week (including a video) = misleading

```

Almost all video content was viewed by a proportionate amount of students in comparison to class size. Some videos were optional recordings which explains why they recieved views less than their class size.

*Note: I cannot see if a student actually watched a video or how long they watched a video, just that they opened it up at the least*
*Note2: There may be missing data here. The logs do not capture what file type a module is, to gather this data I used any module with "Video" or "Recording" in the title which means that videos without clear naming were not used in this visualization.* 

```{r, message=FALSE, warning=FALSE, echo=FALSE}

q52 <- q51 %>%
  group_by(class, numStudents, assignmentid) %>%
  summarise(count = n())

ggplot(q52, aes(x = 1:nrow(q52), y = count, color = numStudents)) + 
  geom_point(size = 3) +
  theme_clean() +
  guides(fill=guide_legend(title="Number of Students in Class")) +
  labs(x = "Moodle Video ID",
       y = "Number of Views",
       title = "How Many Students Watched Video Content on Moodle",
       color = "Number of Students in Class")
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}

```


## I would like to know more about how often students access Moodle in general, time of day, number of log-ins. And perhaps average time spent on Moodle overall per session or per day? When I look at logs for my own courses I see a lot of students access to check something, but they don't seem to stay on there very long. I'm wondering if this is about usage vs. course design.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
##q61
##answered by above graphs
## can not see how long someone was on moodle

## try and answer with
## check each log for a user id
## if time between current log and next log is > 10 min, session prob ended at the last log
## if time between current log and next log is < 10 min, session prob still going
## maybe select most common module type used during block as a bonus
## plot most common time blocks, ie, a lot took place at 9:00PM - 10:00PM
## this session time does not mean that they left moodle, just that they left the module course, they could be going to a different course


# only user ids that have turned in an assignment or taken a quiz
q6students <- alldata %>%
  filter(Eventname == "A submission has been submitted." | Eventname == "Quiz attempt started") %>%
  select(userid)

q61 <- alldata %>%
  filter(userid %in% q6students$userid)


q61$sessionid <- 0

inc <- function(x){
  eval.parent(substitute(x <- x + 1))
}


q61 <- q61 %>%
  arrange(userid, Time) %>%
  filter(!is.na(userid)) %>%
  mutate(tdiff = Time - lag(Time))

value <- 0
nval <- as.numeric(nrow(q61))
nval <- nval - 3

q6fun <- function(x) {
  for( i in 2:nval){
    if(x[i,20] < 3600){
      if(x[i, 14] != x[i-1,14]){
        x[i,19] <- inc(value)
      } else{
        x[i,19] <- value
      }
    }
    else{
      x[i,19] <- inc(value)
    }
  }
  return(x)
}


q61 <- q6fun(q61)

  

```

```{r, message=FALSE, warning=FALSE, echo=FALSE}

q6students <- alldata %>%
  filter(Eventname == "A submission has been submitted." | Eventname == "Quiz attempt started") %>%
  select(userid)



inc <- function(x){
  eval.parent(substitute(x <- x + 1))
}

q6fun <- function(x, value) {


  
x <- x %>%
  filter(userid %in% q6students$userid)




x$sessionid <- 0


x <- x %>%
  arrange(userid, Time) %>%
  filter(!is.na(userid)) %>%
  mutate(tdiff = Time - lag(Time))

nval <- as.numeric(nrow(x))

  for( i in 2:nval){
    if(x[i,20] < 3600){
      if(x[i, 14] != x[i-1,14]){
        x[i,19] <- inc(value)
      } else{
        x[i,19] <- value
      }
    }
    else{
      x[i,19] <- inc(value)
    }
  }

x$value <- value
  return(x)
}

q661 <- q6fun(com101, 0)
q662 <- q6fun(psy101, q661[1,21] + 1)
q663 <- q6fun(eng101, q662[1,21] + 1)
q664 <- q6fun(mth101, q663[1,21] + 1)
q665 <- q6fun(art157, q664[1,21] + 1)
q666 <- q6fun(ge206, q665[1,21] + 1)
q667 <- q6fun(ce435, q666[1,21] + 1)
q668 <- q6fun(cor120, q667[1,21] + 1)
q669 <- q6fun(eng210, q668[1,21] + 1)
q6610 <- q6fun(ba420, q669[1,21] + 1)
q6611 <- q6fun(ba330, q6610[1,21] + 1)
q6612 <- q6fun(ba431, q6611[1,21] + 1)
q6613 <- q6fun(ba344, q6612[1,21] + 1)

q61 <- rbind(
  q661,
  q662,
  q663,
  q664,
  q665,
  q666,
  q667,
  q668,
  q669,
  q6610,
  q6611,
  q6612,
  q6613
  )

```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

q62 <- q61 %>%
  group_by(sessionid) %>%
  summarise(start = max(Time), end = min(Time)) %>%
  mutate(sessionlength = difftime(start, end, units = "mins")) %>%
  filter(sessionlength < 500) #removes a few extremely long sessions created by moodle admin functions


percentless10 <- q62 %>%
  mutate(less10 = if_else(as.numeric(sessionlength) <= 10, "yes", "no")) %>%
  group_by(less10) %>%
  summarise( percent = 100 * n() / nrow(q62))


q62quantile <- quantile(as.numeric(q62$sessionlength), percentless10[2,2] * 0.01)

ggplot(q62, aes(x = as.numeric(sessionlength))) + 
  geom_histogram(binwidth = 5, color = "white", fill="#c9401e") +
  scale_x_continuous(breaks = pretty_breaks(n = 15)) +
  theme_clean() +
  geom_vline(xintercept=q62quantile, color="blue", linetype="dashed", size=1) +
  geom_text(aes(x=q62quantile + 5, label=paste(round(percentless10[2,2],1),"% of Sessions"), y=4000), colour="blue", angle=90) +
  labs(x = "Session Length (Minutes)",
       y = "Count of Sessions",
       title = "How Long Students Were On Moodle",
       subtitle = paste(round(percentless10[2,2],1), "% of Moodle Sessions are Under 10 Minutes"))
  
summary(as.numeric(q62$sessionlength))



```

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# removes quick hop ons that are less than 10 minutes

q63 <- q62 %>%
  filter(sessionlength > 10 & sessionlength < 500) #removes a few extremely long sessions created by moodle admin functions 

ggplot(q63, aes(x=sessionlength)) + 
  geom_histogram(binwidth = 5, color = "White", fill="#c9401e") +
  scale_x_continuous(breaks = pretty_breaks(n = 15)) +
  theme_clean() +
  labs(x = "Session Length (Minutes)",
       y = "Count of Sessions",
       title = "How Long Students Were On Moodle",
       subtitle = "Sessions Under 10 Minutes Removed")

```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

q64 <- q62 %>%
  filter(sessionlength < 10) %>%
  mutate(roundedstart = format(round_date(start,unit="hour"),"%H:%M"),
         weekday = wday(start, label=TRUE))

q65 <- q62 %>%
  filter(sessionlength > 10) %>%
  mutate(roundedstart = format(round_date(start,unit="hour"),"%H:%M"),
         weekday = wday(start, label=TRUE))

q64heatmap <- q64 %>%
  group_by(weekday, roundedstart) %>%
  summarise(count = n())

## OLD COLORS =   scale_fill_gradient(low = "#d8e1cf", high = "#438484", na.value = "grey50") 
ggplot(q64heatmap, aes(roundedstart, weekday)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
  scale_fill_gradient_tableau() +
  guides(fill=guide_legend(title="Total Sessions")) +
  theme_minimal() +
  labs(title = "Under 10 Minute Moodle Sessions by Day of Week and Hour", x = "Submissions Per Hour", y = "Day of Week") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text.y = element_text(face="bold"), axis.text.x = element_text(face="bold"))  +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10)) +
  geom_text(aes(label = count), size = 3)


q65heatmap <- q65 %>%
  group_by(weekday, roundedstart) %>%
  summarise(count = n())

ggplot(q65heatmap, aes(roundedstart, weekday)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
  scale_fill_gradient_tableau() +
  guides(fill=guide_legend(title="Total Sessions")) +
  theme_minimal() +
  labs(title = "Over 10 Minute Moodle Sessions by Day of Week and Hour", x = "Submissions Per Hour", y = "Day of Week") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text.y = element_text(face="bold"), axis.text.x = element_text(face="bold"))  +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10)) +
  geom_text(aes(label = count), size = 3)

```

```{r, message=FALSE, warning=FALSE, echo=FALSE}

## Average per student
## really indicates how often a student checked things

q66 <- q61 %>%
  group_by(userid, sessionid) %>%
  summarise(start = max(Time), end = min(Time)) %>%
  mutate(sessionlength = difftime(start, end, units = "mins")) %>%
  filter(sessionlength < 500) %>% #removes a few extremely long sessions created by moodle admin function
  group_by(userid) %>%
  summarise(avg = mean(sessionlength))

q67 <- q61 %>%
  group_by(class, sessionid) %>%
  summarise(start = max(Time), end = min(Time)) %>%
  mutate(sessionlength = difftime(start, end, units = "mins")) %>%
  filter(sessionlength < 500) %>%#removes a few extremely long sessions created by moodle admin function
  group_by(class) %>%
  summarise(avg = mean(sessionlength))

summary(as.numeric(q67$avg))
summary(as.numeric(q66$avg))
summary(as.numeric(q62$sessionlength))


```

```{r, message=FALSE, warning=FALSE, echo=FALSE}

## most commonly used event per session

q68 <- q61 %>%
  group_by(sessionid) %>%
  count(Eventname) %>%
  rename(count = n) %>%
  slice_max(Eventname, n = 1) %>% # top 1 events per session
  group_by(Eventname) %>%
  summarise(count2 = n()) %>%
  filter(count2 > 50) #removes uncommon events to trim visualization

ggplot(q68, aes(x = reorder(Eventname, count2, FUN = sum), y = count2)) + 
  geom_col(fill="#c9401e") + 
  coord_flip() +
  theme_clean() +
  labs(x = "Event Name",
       y = "Count",
       title = "Which Actions Were Most Commonly Used In a Session")

################### not great predictor ##########
## number of logs per session
# q69 <- q61 %>%
#   group_by(sessionid) %>%
#   summarise(count = n()) %>%
#   filter(count < 50)
# 
# q69 <- inner_join(q69, q62, by = c("sessionid" = "sessionid"))
# q69$sessionlength <- as.numeric(q69$sessionlength)
# 
# mod1 <- lm(sessionlength ~ count + start, data = q69)
# 
# summary(mod1)
# 
# res <- mod1$residuals
# fvalues <- mod1$fitted.values
# temp <- cbind(q69, res, fvalues)
# 
# # ggplot(temp, aes(x=fvalues, y=res)) + 
# #   geom_point() +
# #   geom_smooth()
# 
# ggplot(temp, aes(x=as.factor(count), y=res)) + 
#   geom_boxplot() +
#   coord_flip()
# 
# ggplot(q69, aes(x=count, y = sessionlength)) + geom_point() + geom_smooth(se = FALSE, method = lm)
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

##sessions per day

q69 <- q61 %>%
  group_by(userid, sessionid) %>%
  summarise(start = max(Time), end = min(Time)) %>%
  mutate(sessionlength = difftime(start, end, units = "mins")) %>%
  filter(sessionlength < 500) %>% #removes a few extremely long sessions created by moodle admin function
  mutate(day = day(start),
         month = month(start)) %>%
  ungroup() %>%
  group_by(day, month, userid) %>%
  summarise(sessions = n())

summary(q69$sessions)
##average is 1.8
# means we can assume students are checking all the classes they need to twice a day

ggplot(q69, aes(x=as.factor(sessions))) + 
  geom_bar(fill="#c9401e") +
  theme_clean() +
  labs(x = "Number of Sessions Per Day",
       y = "Count",
       title = "How Many Times Students Visited Moodle Each Day",
       subtitle = paste("Average = ", round(mean(q69$sessions),1), "Sessions Per Day"))

```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

## idk if i wanna keep this

## time series of number of overall sessions
## see if midterms meant anything

q692 <-  q61 %>%
  group_by(userid, sessionid) %>%
  summarise(start = max(Time), end = min(Time)) %>%
  mutate(sessionlength = difftime(start, end, units = "mins")) %>%
  filter(sessionlength < 500) %>% #removes a few extremely long sessions created by moodle admin function
  mutate(date = as.Date(start, "%m/%d/%Y")) %>%
  ungroup() %>%
  group_by(date) %>%
  summarise(sessions = n())

ggplot(q692, aes(x=date, y=sessions)) + geom_point() + scale_x_date() + geom_smooth()

```

## I also have the same question below about when do students access an assignment vs. turn it in, and the question about when (or frankly IF) students access instructor feedback and maybe even how long they spend accessing that feedback. 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
##q71
##find how many students never viewed feedback
## note - for feedback to show sutdents have to press the + button
## not show how many did not view feedback at all or only looked at the score shown without pressing the "+" and left the module 
## meaning == number of students that actually did not view is likley lower but the logs are limited

```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

  temp <- ce435 %>%
    filter(Eventname %in% c("Feedback viewed", "The submission has been graded.", "The status of the submission has been viewed.", "A submission has been submitted."))

```

```{r, message=FALSE, warning=FALSE, echo=FALSE}



```